{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from transformers import AutoImageProcessor, Swinv2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pre_trained = False # True - load the model already trained and saved, False - train the model\n",
    "\"\"\"\n",
    "When save_input_classes = True and save_train_test_splitting = True,\n",
    "the initial splitting of the data into training and test sets is performed.\n",
    "\"\"\"\n",
    "save_input_classes = True\n",
    "save_train_test_splitting = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/content/gdrive/MyDrive/'\n",
    "CURR_PATH = '/content/gdrive/MyDrive/Colab Notebooks/'\n",
    "\n",
    "FILE_NAME = CURR_PATH + 'model_seg_pytorch_medical.cnn'   # to save the model check-points during the training\n",
    "FILE_NAME_PR = CURR_PATH + 'model_seg_pytorch_medical.cnn_23' # the pre-trained model\n",
    "\n",
    "r_size = 256\n",
    "batch_size = 16\n",
    "ep_num = 22\n",
    "\n",
    "zip_name = 'ISSBI2015.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(DATA_PATH + zip_name, 'r') as f:\n",
    "    names = f.namelist()\n",
    "\n",
    "len(names), names[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [n.split('/')[-1] for n in names]\n",
    "names = list(filter(lambda x: (x != '' and x != 'data.csv' and x != 'README.md'), names))\n",
    "names[0], len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_names = [ 'ISSBI2015/' + n[:8]+n[9] + '/' + n for n in names]\n",
    "f_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_images = list(filter(lambda x: 'mask' not in x, f_names))\n",
    "f_images[0], len(f_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_masks = list(filter(lambda x: 'mask' in x, f_names))\n",
    "f_masks[0], len(f_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del f_names\n",
    "del f_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_input_sample(f_images):\n",
    "    random.shuffle(f_images)\n",
    "    with ZipFile(DATA_PATH + zip_name) as archive:\n",
    "        data = archive.read(f_images[0])\n",
    "        print(f_images[0][:-5] + '+mask.tiff')\n",
    "        data1 = archive.read(f_images[0][:-5] + '+mask.tiff')\n",
    "\n",
    "    img = cv2.imdecode(np.frombuffer(data, np.uint8), 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    mask = cv2.imdecode(np.frombuffer(data1, np.uint8), 1)\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    print(mask.max(), mask.min(), np.unique(mask))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 10))\n",
    "    axes[0].imshow(img)\n",
    "    axes[1].imshow(mask)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_input_sample(f_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_input_classes:\n",
    "    f_images0 = []\n",
    "    f_images1 = []\n",
    "\n",
    "    for f in f_images:\n",
    "        with ZipFile(DATA_PATH + zip_name) as archive:\n",
    "            data = archive.read(f)\n",
    "            print(f[:-5] + '+mask.tiff')\n",
    "            data1 = archive.read(f[:-5] + '+mask.tiff')\n",
    "\n",
    "            mask = cv2.imdecode(np.frombuffer(data1, np.uint8), 1)\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "      #      print(mask.max(),mask.min(),np.unique(mask))\n",
    "            if mask.max() < 127:\n",
    "                f_images0.append(f)\n",
    "            else:\n",
    "                f_images1.append(f)\n",
    "\n",
    "    with open(DATA_PATH + \"fN_im0.txt\", \"w\") as fl:\n",
    "        for f in f_images0:\n",
    "            fl.write(f + '\\n')\n",
    "\n",
    "    with open(DATA_PATH + \"fN_im1.txt\", \"w\") as fl:\n",
    "        for f in f_images1:\n",
    "            fl.write(f + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + \"fN_im0.txt\", \"r\") as fl:\n",
    "    f_images0 = fl.readlines()\n",
    "\n",
    "f_images0 = [f.strip() for f in f_images0]\n",
    "\n",
    "with open(DATA_PATH + \"fN_im1.txt\", \"r\") as fl:\n",
    "    f_images1 = fl.readlines()\n",
    "\n",
    "f_images1 = [f.strip() for f in f_images1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f_images0), len(f_images1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_input_sample(f_images1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_input_sample(f_images0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_train_test_splitting:\n",
    "    random.shuffle(f_images0)\n",
    "    train_len0 = int(0.9 * len(f_images0))\n",
    "    df_train0 = f_images0[:train_len0]\n",
    "    df_test0 = f_images0[train_len0:]\n",
    "\n",
    "    random.shuffle(f_images1)\n",
    "    train_len1 = int(0.9 * len(f_images1))\n",
    "    df_train1 = f_images1[:train_len1]\n",
    "    df_test1 = f_images1[train_len1:]\n",
    "\n",
    "    #To make a balanced training dataset:\n",
    "\n",
    "    diff = len(df_train0) - len(df_train1)\n",
    "    random.shuffle(df_train1)\n",
    "    df_train1.extend(df_train1[:diff])\n",
    "\n",
    "    df_train = df_train0\n",
    "    df_test = df_test0\n",
    "\n",
    "    df_train.extend(df_train1)\n",
    "    df_test.extend(df_test1)\n",
    "\n",
    "    with open(DATA_PATH + 'dfN_train.txt', 'w') as fl:\n",
    "        for f in df_train0:\n",
    "            fl.write(f + '\\n')\n",
    "\n",
    "    with open(DATA_PATH + 'dfN_test.txt', 'w') as fl:\n",
    "        for f in df_test0:\n",
    "            fl.write(f + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH + 'dfN_train.txt', 'r') as fl:\n",
    "    df_train = fl.readlines()\n",
    "df_train = [f.strip() for f in df_train]\n",
    "\n",
    "with open(DATA_PATH + 'dfN_test.txt', 'r') as fl:\n",
    "    df_test = fl.readlines()\n",
    "df_test = [f.strip() for f in df_test]\n",
    "\n",
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to verify that the test data is not included in the training set\n",
    "for dl in df_test:\n",
    "    if dl in df_train:\n",
    "        print('test line in the train set!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, Swinv2Config, Swinv2Model\n",
    "\n",
    "# مرحله اول: لود کانفیگ مدل\n",
    "config = Swinv2Config.from_pretrained(\"microsoft/swinv2-large-patch4-window12-192-22k\")\n",
    "\n",
    "# مرحله دوم: ساخت مدل بدون بارگذاری وزن‌های آموزش‌دیده\n",
    "model_seg = Swinv2Model(config).to(device)\n",
    "\n",
    "# مرحله سوم: لود پردازشگر ورودی مثل قبل (می‌تونی نگه داری چون مربوط به ورودی‌هاست نه وزن مدل)\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swinv2-large-patch4-window12-192-22k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swinv2-large-patch4-window12-192-22k\")\n",
    "#model_seg = Swinv2Model.from_pretrained(\"microsoft/swinv2-large-patch4-window12-192-22k\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 gen_df,\n",
    "                 transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((r_size, r_size), interpolation=transforms.InterpolationMode.NEAREST_EXACT)\n",
    "                 ]),\n",
    "                 mask_color='GRAY'):\n",
    "        self.gen_df = gen_df\n",
    "        self.transform = transform\n",
    "        self.mask_color = mask_color\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.gen_df[index]\n",
    "\n",
    "        with ZipFile(DATA_PATH + zip_name) as archive:\n",
    "            data = archive.read(img_name)\n",
    "            data1 = archive.read(img_name[:-5] + '+mask.tiff')\n",
    "\n",
    "        img = cv2.imdecode(np.frombuffer(data, np.uint8), 1)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mask = cv2.imdecode(np.frombuffer(data1, np.uint8), 1)\n",
    "        if self.mask_color == 'GRAY':\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        img_in = self.transform(img)\n",
    "        mask = self.transform(mask)\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "        img = image_processor(images=img, return_tensors=\"pt\")\n",
    "\n",
    "        x = model_seg.embeddings(**img.to(device))\n",
    "        input_dimensions=x[1]\n",
    "        img0 = x[0].detach().squeeze(0)\n",
    "\n",
    "        x = model_seg.encoder.layers[0](x[0], input_dimensions=input_dimensions)\n",
    "        img1 = x[0].detach().squeeze(0)\n",
    "\n",
    "        x = model_seg.encoder.layers[1](x[0], input_dimensions=(input_dimensions[0]//2, input_dimensions[1]//2) )\n",
    "        img2 = x[0].detach().squeeze(0)\n",
    "\n",
    "        x = model_seg.encoder.layers[2](x[0], input_dimensions=(input_dimensions[0]//4, input_dimensions[1]//4) )\n",
    "        img3 = x[0].detach().squeeze(0)\n",
    "\n",
    "        x = model_seg.encoder.layers[3](x[0], input_dimensions=(input_dimensions[0]//8, input_dimensions[1]//8) )\n",
    "        x = model_seg.layernorm(x[0])\n",
    "        img4 = x.detach().squeeze(0)\n",
    "\n",
    "        return img0, img1, img2, img3, img4, mask, img_in\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gen_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_dataset = SegmentDataset(df_train, mask_color='RGB')\n",
    "\n",
    "try_dataloader = DataLoader(try_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0,\n",
    "                        batch_size=8)\n",
    "dataiter = iter(try_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0, i1, i2, i3, i4, y, x1 = next(dataiter)\n",
    "print(i0.shape, i1.shape, i2.shape, i3.shape, i4.shape)\n",
    "print(y.shape, x1.shape)\n",
    "\n",
    "concatenated = torch.cat((x1, y),0)\n",
    "c_img = torchvision.utils.make_grid(concatenated).permute(1, 2, 0)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(c_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del try_dataloader\n",
    "del try_dataset\n",
    "del concatenated\n",
    "del c_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SegmentDataset(df_train, mask_color='GRAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up_Linear(nn.Module):\n",
    "    def __init__(self, in_ch, size, coef=1):\n",
    "        super(Up_Linear, self).__init__()\n",
    "        self.shuffle = nn.PixelShuffle(upscale_factor=2)\n",
    "\n",
    "        n_ch = int(coef * in_ch)\n",
    "\n",
    "        self.ln = nn.Sequential(\n",
    "            nn.Linear(in_ch * 2, n_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_ch, in_ch * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x = torch.cat((x1, x2), 2)\n",
    "        x = self.ln(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = torch.reshape(x, (x.shape[0], x.shape[1], self.size, self.size))\n",
    "        x = self.shuffle(x)\n",
    "        x = torch.reshape(x, (x.shape[0], x.shape[1], self.size*self.size*4))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "class MRI_Seg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MRI_Seg, self).__init__()\n",
    "\n",
    "        self.ups3 = Up_Linear(1536, 6, 1)\n",
    "        self.ups2 = Up_Linear(768, 12, 1)\n",
    "        self.ups1 = Up_Linear(384, 24, 2)\n",
    "        self.ups0 = Up_Linear(192, 48, 3)\n",
    "\n",
    "        self.shuffle = nn.PixelShuffle(upscale_factor=2)\n",
    "\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(24, 1, kernel_size=1, stride=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x0, x1, x2, x3, x4):\n",
    "        x = self.ups3(x4, x3)\n",
    "        x = self.ups2(x, x2)\n",
    "        x = self.ups1(x, x1)\n",
    "        x = self.ups0(x, x0)\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = torch.reshape(x, (x.shape[0], x.shape[1], 96, 96))\n",
    "        x = self.shuffle(x)\n",
    "        x = transforms.Resize((256, 256))(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0,\n",
    "                        batch_size=batch_size)\n",
    "\n",
    "net = MRI_Seg().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "lr = 0.0001\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_dataloader)\n",
    "i0, i1, i2, i3, i4, y, x1 = next(dataiter)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 10))\n",
    "\n",
    "axes[0].imshow(y[0].permute(1, 2, 0))\n",
    "axes[1].imshow(x1[0].permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=net, input_size=[(1, 2304, 192), (1, 576, 384), (1, 144, 768), (1, 36, 1536), (1, 36, 1536)], col_names=['input_size', 'output_size', 'num_params', 'trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(Variable(i0).to(device), Variable(i1).to(device), Variable(i2).to(device), Variable(i3).to(device), Variable(i4).to(device))\n",
    "print(out.shape, y[0].shape)\n",
    "print(y[0].max())\n",
    "\n",
    "ls = criterion(out[0], Variable(y[0]).to(device))\n",
    "\n",
    "print(ls)\n",
    "plt.imshow(out[0].cpu().detach().numpy()[0])\n",
    "del out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net():\n",
    "    num_iter = len(train_dataloader)\n",
    "    ep_init = 0\n",
    "\n",
    "    for epoch in range(ep_init, ep_num):\n",
    "        sum_loss = 0\n",
    "        print(\"Epoch number: {}\".format(epoch))\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "\n",
    "            img0, img1, img2, img3, img4, mask, img_in = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x0 = Variable(img0).to(device)\n",
    "            x1 = Variable(img1).to(device)\n",
    "            x2 = Variable(img2).to(device)\n",
    "            x3 = Variable(img3).to(device)\n",
    "            x4 = Variable(img4).to(device)\n",
    "\n",
    "            output = net(x0, x1, x2, x3, x4)\n",
    "            # label.squeeze() - to transform lables to 1-dim vector\n",
    "            # without squeeze() loss calculation is incorrect\n",
    "            loss_bce = criterion(output, Variable(mask).to(device))\n",
    "            loss_bce.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            sum_loss += loss_bce.data\n",
    "            if i % 10 == 0:\n",
    "                print('{} ===================  {}'.format(i, sum_loss/(i + 1)))\n",
    "\n",
    "        print(\"Epoch number: {}, Num iter: {}, lr: {}, Current loss: {}\".format(epoch, num_iter, optimizer.param_groups[0]['lr'], sum_loss/num_iter))\n",
    "        torch.save(net, FILE_NAME + '_{}'.format(epoch + 1))\n",
    "\n",
    "    torch.save(net, FILE_NAME)\n",
    "    print(\"The pre-trained model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pre_trained is False:\n",
    "    net.train().to(device)\n",
    "    train_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rect(img_mask):\n",
    "    ind = np.argwhere(img_mask >= 0.5)\n",
    "    if len(ind) == 0:\n",
    "        return None, None\n",
    "    top_y = min(ind[:,0])\n",
    "    bottom_y = max(ind[:,0])\n",
    "    top_x = min(ind[:,1])\n",
    "    bottom_x = max(ind[:,1])\n",
    "    return (top_x, top_y), (bottom_x, bottom_y)\n",
    "\n",
    "def show_results(i0, i1, i2, i3, i4, y, x1, im_id):\n",
    "    ii0 = Variable(i0).to(device)\n",
    "    ii1 = Variable(i1).to(device)\n",
    "    ii2 = Variable(i2).to(device)\n",
    "    ii3 = Variable(i3).to(device)\n",
    "    ii4 = Variable(i4).to(device)\n",
    "    pred = net(ii0, ii1, ii2, ii3, ii4)\n",
    "    pr = pred[im_id].cpu().detach().numpy()[0]\n",
    "\n",
    "    xim = copy.deepcopy(x1[im_id].permute(1, 2, 0).cpu().detach().numpy())\n",
    "    # just to transform numpy array to cv2 image:\n",
    "    xim = cv2.resize(xim, (r_size, r_size))\n",
    "    top_left, bottom_right = calc_rect(pr)\n",
    "    if top_left is not None:\n",
    "        cv2.rectangle(xim, top_left, bottom_right, (255, 0, 0), 2)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 15))\n",
    "    axes[0].imshow(y[im_id].cpu().detach().numpy()[0])\n",
    "    axes[1].imshow(pr > 0.5)\n",
    "    axes[2].imshow(xim)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pre_trained:\n",
    "    del net\n",
    "    net = torch.load(FILE_NAME_PR)\n",
    "    print(\"The pre-trained model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(i0, i1, i2, i3, i4, y, x1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader1 = DataLoader(train_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0,\n",
    "                        batch_size=1)\n",
    "\n",
    "test_dataset = SegmentDataset(df_test)\n",
    "test_dataloader2 = DataLoader(test_dataset,\n",
    "                        shuffle=False,\n",
    "                        num_workers=0,\n",
    "                        batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(test_dataloader1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0, i1, i2, i3, i4, y, x1 = next(dataiter)\n",
    "show_results(i0, i1, i2, i3, i4, y, x1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(test_dataloader, set_id, model, sample_num=None):\n",
    "    batch_size = 1\n",
    "    if not sample_num:\n",
    "        N = len(test_dataloader)\n",
    "    else:\n",
    "        if sample_num <= 0:\n",
    "            sample_num = len(test_dataloader)\n",
    "        N = min(sample_num, len(test_dataloader))\n",
    "\n",
    "    And = 0\n",
    "    Uni = 0\n",
    "    Uni_dice = 0\n",
    "\n",
    "    T0 = 0\n",
    "    T1 = 0\n",
    "    F0 = 0\n",
    "    F1 = 0\n",
    "\n",
    "    for i, data in enumerate(test_dataloader, 0):\n",
    "        #xx, yy, xs = data\n",
    "        img0, img1, img2, img3, img4, yy, xs = data\n",
    "\n",
    "        x0 = Variable(img0).to(device)\n",
    "        x1 = Variable(img1).to(device)\n",
    "        x2 = Variable(img2).to(device)\n",
    "        x3 = Variable(img3).to(device)\n",
    "        x4 = Variable(img4).to(device)\n",
    "\n",
    "        xx1 = model(x0, x1, x2, x3, x4)\n",
    "        xx1 = xx1[0][0].cpu().detach().numpy()\n",
    "        yy = yy[0][0].cpu().detach().numpy()\n",
    "        xx1[xx1 >= 0.5 ] = 1\n",
    "        xx1[xx1 < 0.5 ] = 0\n",
    "\n",
    "        owl = np.sum(xx1*yy)\n",
    "        And += owl\n",
    "        a_uni_dice = np.sum(xx1 + yy)\n",
    "        a_uni = a_uni_dice - owl\n",
    "        Uni += a_uni\n",
    "        Uni_dice += a_uni_dice\n",
    "\n",
    "        if xx1.max() == 0 and yy.max() == 0:\n",
    "            T0 += 1\n",
    "        if xx1.max() == 1 and yy.max() == 1:\n",
    "            T1 += 1\n",
    "        if xx1.max() == 0 and yy.max() == 1:\n",
    "            F0 += 1\n",
    "        if xx1.max() == 1 and yy.max() == 0:\n",
    "            F1 += 1\n",
    "\n",
    "        print('{}:  i = {}, And = {}, Uni = {}'.format(set_id, i, And, Uni))\n",
    "\n",
    "        if i >= N - 1:\n",
    "            break\n",
    "\n",
    "    IoU_av = And / Uni\n",
    "    Dice = 2*And / Uni_dice\n",
    "\n",
    "    return  IoU_av, Dice, T0, T1, F0, F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IoU_tr, Dice_tr, T0_tr, T1_tr, F0_tr, F1_tr = calc_accuracy(test_dataloader1, 'train', net, sample_num=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training set: IoU = {}, Dice = {}, True_0 = {}, True_1 = {}, False_0 = {}, False_1 = {}'.format(IoU_tr, Dice_tr, T0_tr, T1_tr, F0_tr, F1_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IoU_ts, Dice_ts, T0_ts, T1_ts, F0_ts, F1_ts = calc_accuracy(test_dataloader2, 'test', net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test set: IoU = {}, Dice = {}, True_0 = {}, True_1 = {}, False_0 = {}, False_1 = {}'.format(IoU_ts, Dice_ts, T0_ts, T1_ts, F0_ts, F1_ts))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
